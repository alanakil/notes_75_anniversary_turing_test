# Re-minding and re-asking about humans and thought
Alan Kay, Computer Science Pioneer and Adjunct Professor at UCLA.

- Humans are not just easily fooled, but they want to be fooled. And they even pay to be fooled!
- Transportation changed in the 20th century from using horses to cars. But what about safety? Well, the cost we are willing to pay is 1.2M deaths/year. In fact, this is the #1 cause fo death ages 1-19.
- Mind that eyes and ears detect changes in photon intensity and air pressure fluctuations. So brains create both end of a conversation!
  - We live ina  waking hallucination dream.
- D. Kahneman "Expository fictions": System 1 vs System 2 (slow vs fast thinking) -> our normal state is delusional
  - 1966 Eliza, the first chatbot. Slow thinking knows it's a program, fast thinks it's a friend.
- Book: Human Universals by Donald Brown.
- Kay: "The main theme of the 21st century should be safety".
- Bureaucracy is the most dangerous enemy.
- More is better... until it isn't.

# Panel discussion: What did Turing mean? And how was it interpreted?
Sarah Dillon, University of Cambridge.
Thomas Irvine, University of Southampton.
Steven Harnard, University of Southampton and Universite du Quebec a Montreal.
Alan Kay, Computer Science Pioneer and Adjunct Professor at UCLA.

- Turing's paper was propaganda: he wanted people to start thinking about the problem of "Can machines think?".
- Not all of it is to be taken seriously: Turing frequently joked/trolled.
- There were 7 imitation games, not just 1.
- LLMs show that the Turing test does not matter. Most humans wouldn't even pass the test.

# The Grand AGI Delusion / Turing's test today
Gary Marcus, Professor Emeritus at New York University.

- The first line of Turing's 1950 paper: "Can machines think?" is still a very valid question today.
- However, the TT did not really stand the test of time.
- "The Eliza effect" -> LLMs prey on this effect.
- Society is betting massively on closing in on AGI, and we are overattributing intelligence to LLMs because they can fool us.
- Marcus reviewed several examples of LLMs being dumb (goat river problem, image generation on clocks, etc.).
- AI systems fail when they are pushed out of the data that they are familiar with (out of distribution).
- Richard Sutton's: The Bitter Lesson.
- Scaling alone will not lead to AGI, in fact it will not even solve hallucinations + reasoning.
- CEOs imply that scaling is a law of the universe, when in fact it isn't. It is just empirical observations, like Moore's law.
- Scaling does help on certain problems of course (pattern recognition, etc.), but it does not solve it all (plan, reason, reliability).
- Imitation $\neq$ Intelligence.
- Payoff:
  - 95% of businesses had zero measurable business impact when incorporating AI.
  - FOMO.
  - Workslop -> AI work that masquerades as good work.
- Book: Charles Mackay 1841 about the Tulip bubble.
- It is liekly we won't find the one true algorithm for AGI, because the mind works in many different ways.
  - Human brains have specialized circuits that perform different computations, but LLMs don't.
- AlphaFold3 is a great example of AI, because it has specialized components to do specific things and works really well.
- Fast vs slow systems -> Fast: LLMs
- Neurosymbolic AI aims at combining the two, as they are combined in the human brain.
- We should make world models (cognitive models) the centerpiece rather than an afterthought.

# Panel discussion: How is the Turing test being used today and is it still relevant?
Abeba Birhane, AI Accountability Lab.
Yarin Gal, University of Oxford and AI Security Institute.
Kaitlyn Regehr, University College London.
Gary Marcus, Professor Emeritus at New York University.

- How much of the development of our thinking is safe to offload?
  - What if we don't learn to write emails? What if we don't learn to message/communicate with others?
  - Kaitlyn Regehr shared an anecdote where a 15-year old was not confident enough to write messages to her friends, and asked ChatGPT to write them.
- How will we stop perpetuating past bias in AI?
- Book: Kaitlyn Regehr "Smartphone Nation"
- "We don't need to make machines more intelligent, we need to make humans more intelligent".
- EdTech push back:
  - 10 years ago: give an iPad to every kid.
  - Now: Take the iPads from all kids.
  - Now also: give them AI.
  - In 10 years: ?

# Varieties of intelligence: Evolving the Turing Test
Nigel Shadbolt, University of Oxford.

- Patrick Winston: "There are many ways of being smart that are not smart like us".
- Varieties of intelligence:
  - Navigation and memory
  - Distributed problem solving
  - Tool use and foresight
  - Sensor motor genius
  - Communication
  - Self awareness
  - Cultural transmission
  - Planning and foresight
- Broad review of AI
- Prospects: Integrating learning and reasoning; embodiment
- The hard problem is sentience
- Do not forget about humanity

# Panel discussion: What is, or will be AGI? What should the Turing Test for the future be?
William Isaac, Google DeepMind.
Anil Seth, University of Sussex.
Shannon Vallor, University of Edinburgh.
Nigel Shadbolt, University of Oxford.

- Intelligence $\neq$ Consciousness
- Brain $\neq$ Computer
- Some made the point that Conscious AI is undesirable because of the ethical problems that would follow.
- Naming hallucinations that way is problematic, because they imply that the LLMs experience things when they don't. Confabulations may be a better word.
- Today's LLMs have jagged intelligence.
- Juxtaposition: they are very good at some things, pretty bad at others. This confuses people.
- Does AI add meaningful value to your life?
- CEOs speak of AGI and they always speak of it in the future, but this clouds today's issues while hoping for a dystopian amazing future.
  - Issues ignored because of the rhetoric: deskilling, hallucinations, reward hacking, etc.
- There's been a massive appropriation of public goods (data) without real consequence.
- We all are passengers in a bus driven by others hoping that it takes us somewhere nice.
- The concept of AGI is disempowering because it is said that we are going to a dystopian world and we have no say in it.
